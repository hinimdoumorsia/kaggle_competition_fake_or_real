#  Fake or Real : Lâ€™imposteur â€“ CompÃ©tition Kaggle
---
<p align="center">
  <img src="https://img.shields.io/badge/Python-3.11-3776AB?logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/Pandas-1.x-150458?logo=pandas&logoColor=white" />
  <img src="https://img.shields.io/badge/Numpy-1.x-013243?logo=numpy&logoColor=white" />
  <img src="https://img.shields.io/badge/Scikit-learn-1.x-F7931E?logo=scikit-learn&logoColor=white" />
  <img src="https://img.shields.io/badge/TensorFlow-2.x-FF6F00?logo=tensorflow&logoColor=white" />
  <img src="https://img.shields.io/badge/PyTorch-2.x-EE4C2C?logo=pytorch&logoColor=white" />
  <img src="https://img.shields.io/badge/SpaCy-3.x-FF0000?logo=spacy&logoColor=white" />
  <img src="https://img.shields.io/badge/GloVe-300d-1A1A1A?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAKCAYAAACNMs+9AAAAF0lEQVQYV2NggAKGBgYmBgYGBiYGAAAwAE9+CBcUAAAAASUVORK5CYII=" />
  <img src="https://img.shields.io/badge/Jupyter-Notebook-F37626?logo=jupyter&logoColor=white" />
  <img src="https://img.shields.io/badge/Matplotlib-3.x-11557C?logo=matplotlib&logoColor=white" />
  <img src="https://img.shields.io/badge/Seaborn-0.12-4C72B0?logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/NLP-Text%20Processing-008080" />
  <img src="https://img.shields.io/badge/ML-Classification-6F42C1" />
</p>

---
Ce dÃ©pÃ´t contient mon approche pour la compÃ©tition Kaggle  
**[Fake or Real: The Impostor Hunt](https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt)**.

Le but est de dÃ©velopper un **modÃ¨le de classification de texte** permettant de diffÃ©rencier un **texte gÃ©nÃ©rÃ© par une IA** dâ€™un **texte Ã©crit par un humain**.

---

##  Approche

Plusieurs approches ont Ã©tÃ© utilisÃ©es pour approcher le problÃ¨me, incluant **prÃ©traitement du texte**, **reprÃ©sentation des donnÃ©es**, et **modÃ©lisation**.

---

## ğŸ“‚ AperÃ§u des donnÃ©es

**Exemple du jeu dâ€™entraÃ®nement :**

| text | label |
|------|-------|
| The VIRSA (Visible Infrared Survey Telescope Array) observes galaxies. | 1 |
| The China relay network has released a significant amount of data. | 0 |
| The project aims to achieve an accuracy level of 95%. | 1 |
| China\nThe goal of this project involves achieving better coverage. | 0 |
| Scientists can learn about how galaxies form and evolve. | 1 |

- **Total exemples dâ€™entraÃ®nement :** 190  

**Exemple du jeu de test :**

| article_id | text |
|------------|------|
| article_0000_1 | "Music" Music music music Music music Music mu... |
| article_0000_2 | Since its launch on Paranal observatory's Very... |
| article_0001_1 | underground exploration on SN's birth has prov... |
| article_0001_2 | SN 1987A provides valuable insights as newer o... |
| article_0002_1 | This research aimed to understand how star sha... |

- **Total exemples de test :** 2,136

---

##  PrÃ©traitement du texte â€“ Ã‰tapes expliquÃ©es

Pour chaque texte du dataset `df_dataset` :

1ï¸âƒ£ **Mise en minuscules**  
Standardiser tous les mots pour que `"China"` et `"china"` soient considÃ©rÃ©s identiques.  

| Texte original | AprÃ¨s mise en minuscules |
|----------------|------------------------|
| The VIRSA observes galaxies. | the virsa observes galaxies |
| China 2025 report! | china 2025 report! |

2ï¸âƒ£ **Suppression de la ponctuation et des nombres**  
Supprimer tous les caractÃ¨res non alphabÃ©tiques (ponctuation, chiffres, symboles).  

| AprÃ¨s minuscules | AprÃ¨s suppression ponctuation/nombres |
|-----------------|--------------------------------------|
| the virsa observes galaxies | the virsa observes galaxies |
| china 2025 report! | china report |

3ï¸âƒ£ **Tokenisation**  
Diviser le texte en mots (tokens).  

| Texte nettoyÃ© | Tokens |
|---------------|--------|
| the virsa observes galaxies | [the, virsa, observes, galaxies] |
| china report | [china, report] |

4ï¸âƒ£ **Suppression des stopwords et lemmatisation**  
- Stopwords : mots frÃ©quents mais peu informatifs (`the`, `a`, `has`, etc.)  
- Lemmatisation : rÃ©duire les mots Ã  leur racine (`observes â†’ observe`, `galaxies â†’ galaxy`)  

| Tokens | AprÃ¨s suppression des stopwords & lemmatisation |
|--------|-----------------------------------------------|
| [the, virsa, observes, galaxies] | [virsa, observe, galaxy] |
| [china, has, released, report] | [china, release, report] |

5ï¸âƒ£ **Reconstruction de la phrase nettoyÃ©e**  
Assembler les tokens filtrÃ©s en une phrase pour le modÃ¨le.  

| Tokens lemmatisÃ©s | clean_text |
|------------------|------------|
| [virsa, observe, galaxy] | virsa observe galaxy |
| [china, release, report] | china release report |

---

##  Exemple final dans `df_dataset`

| Original Text | clean_text | tokens | label |
|---------------|------------|--------|-------|
| The VIRSA observes galaxies. | virsa observe galaxy | [virsa, observe, galaxy] | 1 |
| China has released a report. | china release report | [china, release, report] | 0 |
| The project aims to achieve an accuracy level of 95%. | project aim achieve accuracy level | [project, aim, achieve, accuracy, level] | 1 |
| China\nThe goal of this project involves achieving better coverage. | china goal project involve achieve better coverage | [china, goal, project, involve, achieve, better, coverage] | 0 |
| Scientists can learn about how galaxies form and evolve. | scientist learn galaxy form evolve | [scientist, learn, galaxy, form, evolve] | 1 |

---

##  RÃ©sultats du dataset dâ€™entraÃ®nement

| text | cible | clean_text | tokens |
|------|-------|------------|--------|
| The VIRSA (Visible Infrared Survey Telescope Array) observes galaxies. | 1 | virsa visible infrared survey telescope array observe galaxy | [virsa, visible, infrared, survey, telescope, array, observe, galaxy] |
| The China relay network has released a significant amount of data. | 0 | china relay network released significant amount data | [china, relay, network, released, significant, amount, data] |
| The project aims to achieve an accuracy level of 95%. | 1 | project aim achieve accuracy level dex analyzing | [project, aim, achieve, accuracy, level, dex, analyzing] |
| China\nThe goal of this project involves achieving better coverage. | 0 | china goal project involves achieving accuracy coverage | [china, goal, project, involves, achieving, accuracy, coverage] |
| Scientists can learn about how galaxies form and evolve. | 1 | scientist learn galaxy form evolve two methods | [scientist, learn, galaxy, form, evolve, two, methods] |

---

## Chargement des embeddings GloVe (300d) pour NLP

### IdÃ©e principale
Le code charge des vecteurs de mots prÃ©-entraÃ®nÃ©s depuis GloVe et les stocke dans un dictionnaire Python.  
Chaque mot est associÃ© Ã  un vecteur numÃ©rique reprÃ©sentant son sens.  
Ces vecteurs sont ensuite utilisÃ©s dans des modÃ¨les NLP (classification, traduction, rÃ©sumÃ©, etc.).

### Quâ€™est-ce que GloVe ?
GloVe (Global Vectors for Word Representation) transforme les mots en vecteurs de nombres rÃ©els.  
Exemple : `vec("king") - vec("man") + vec("woman") â‰ˆ vec("queen")`.  
Ces vecteurs sont entraÃ®nÃ©s sur de grands corpus pour capturer les relations entre les mots.

### UtilitÃ©
- Permet aux modÃ¨les NLP de comprendre le sens des mots.  
- Ã‰vite dâ€™entraÃ®ner vos propres embeddings.  
- Ã‰conomise du temps et des ressources computationnelles.

---

##  CrÃ©ation de vecteurs de documents avec GloVe

### IdÃ©e principale
- Si un mot nâ€™est pas trouvÃ© dans GloVe, il est remplacÃ© par un vecteur nul.  
- Sinon, la moyenne des vecteurs des mots du document est calculÃ©e pour reprÃ©senter le document.  
- La matrice rÃ©sultante `X_glove` contient une ligne par document.  

### UtilitÃ©
- Transformer du texte en vecteurs numÃ©riques est essentiel pour les tÃ¢ches NLP.  
- Ces vecteurs de documents peuvent Ãªtre utilisÃ©s pour :
  - Classification de texte
  - Analyse de sentiment
  - Clustering ou recherche de similaritÃ©

### Comment Ã§a fonctionne
La fonction `document_vector` prend :
- `tokens` : liste des mots du document  
- `embeddings_dict` : embeddings GloVe  
- `dim` : dimension des vecteurs (ici 300)  

Elle rÃ©cupÃ¨re le vecteur de chaque mot trouvÃ© dans GloVe.  
**Forme des vecteurs documents GloVe :** `(190, 300)`  

### Ajout des vecteurs GloVe au DataFrame
- Chaque article est reprÃ©sentÃ© par un vecteur GloVe de 300 dimensions.  
- Ces vecteurs deviennent des colonnes supplÃ©mentaires dans le DataFrame (`glove_0`, `glove_1`, ..., `glove_299`).  
- **Nouvelle forme du DataFrame :** `(190, 304)`  

---

##  Features Named Entity Recognition (NER) pour les articles

### Vue dâ€™ensemble
- Extraction des entitÃ©s nommÃ©es (Person, Organization, Location, Date, etc.) via SpaCy pour chaque mot.  
- RÃ©sultat stockÃ© dans une colonne `ner_tokens` du DataFrame.

### Encodage des entitÃ©s en valeurs numÃ©riques
- Chaque type dâ€™entitÃ© est assignÃ© Ã  un numÃ©ro unique.  
- RÃ©sultat stockÃ© dans la colonne `ner_tokens_numeric`.  
- Permet aux modÃ¨les ML dâ€™utiliser lâ€™information sÃ©mantique pour amÃ©liorer la classification.

---

##  Calcul de nouvelles features textuelles

Pour chaque ligne de `df_dataset`, les nouvelles features calculÃ©es sont :  
- `avg_word_length` â†’ longueur moyenne des mots  
- `num_stopwords` â†’ nombre de stopwords  
- `num_uppercase` â†’ nombre de mots en majuscules  
- `num_punct` â†’ nombre de signes de ponctuation  
- `num_sentences` â†’ nombre de phrases  
- `unique_words_ratio` â†’ ratio mots uniques / total mots  
- `contains_numbers` â†’ prÃ©sence de chiffres  
- `readability_score` â†’ score approximatif Flesch Reading Ease  

**Exemple de DataFrame avec nouvelles features :**  
- **Nombre de colonnes total aprÃ¨s ajout :** 316  

---

##  Traitement du jeu de test
- Les mÃªmes features textuelles sont calculÃ©es pour `df_test`.  
- VÃ©rification et traitement des outliers pour les colonnes numÃ©riques (`num_tokens`, `num_chars`, `avg_word_length`, `num_stopwords`, `readability_score`) via **capping IQR**.

### Outliers dÃ©tectÃ©s dans df_test
| Colonne | Nombre dâ€™outliers |
|---------|-----------------|
| num_tokens | 159 |
| num_chars | 161 |
| avg_word_length | 67 |
| num_stopwords | 25 |
| num_uppercase | 101 |
| num_punct | 185 |
| num_sentences | 19 |
| unique_words_ratio | 30 |
| readability_score | 122 |

- AprÃ¨s capping, les valeurs extrÃªmes sont ajustÃ©es aux bornes IQR.  

---

##  Analyse de corrÃ©lation des features numÃ©riques

- Calcul de la matrice de corrÃ©lation pour les features numÃ©riques de `df_dataset` et visualisation avec **heatmap** (Seaborn).  
- Identification des paires de colonnes fortement corrÃ©lÃ©es (|corr| > 0.8) :

| Feature 1 | Feature 2 | CorrÃ©lation |
|-----------|-----------|------------|
| num_tokens | num_chars | 0.993985 |
| num_uppercase | num_punct | 0.889471 |

---

##  Analyse de lâ€™importance des features fortement corrÃ©lÃ©es par rapport Ã  la cible

| Feature | Correlated With | Correlation | Importance | DÃ©cision | Justification |
|---------|----------------|------------|------------|----------|---------------|
| num_chars | num_tokens | 0.99 | 0.278 | SupprimÃ©e | Fortement corrÃ©lÃ©e et peu importante pour la cible |
| num_uppercase | num_punct | 0.89 | 0.171 | SupprimÃ©e | Fortement corrÃ©lÃ©e et peu importante |
| num_tokens | - | - | 0.283 | ConservÃ©e | Plus importante pour la prÃ©diction |
| num_punct | - | - | 0.269 | ConservÃ©e | Plus importante pour la prÃ©diction |

**Importance finale des features fortement corrÃ©lÃ©es :**

| Feature | Importance |
|---------|-----------|
| num_tokens | 0.282703 |
| num_chars | 0.278086 |
| num_punct | 0.268681 |
| num_uppercase | 0.170530 |

### Analyse corrÃ©lation du jeu test
- CorrÃ©lation forte dÃ©tectÃ©e entre :  
| Feature 1 | Feature 2 | CorrÃ©lation |
|-----------|-----------|------------|
| num_tokens | num_chars | 0.992736 |
| num_tokens | num_punct | 0.831494 |
| num_chars | num_punct | 0.813295 |


         
---
##  Structure du projet

```plaintext
kaggle_competition_fake_or_real/
â”‚
â”œâ”€â”€ notebooks/             # Notebooks Jupyter pour l'entraÃ®nement et l'Ã©valuation
â”‚   â””â”€â”€ main_notebook.ipynb
â”‚
â”œâ”€â”€ glove/                 # Embeddings GloVe prÃ©entraÃ®nÃ©s (300d)
â”‚   â””â”€â”€ glove.6B.300d.txt
â”‚
â”œâ”€â”€ README.md              # Documentation du projet
```
---

Ce README documente donc **la suite du pipeline**, depuis le chargement des embeddings GloVe, lâ€™extraction NER, la crÃ©ation de nouvelles features textuelles, le traitement des outliers, jusquâ€™Ã  lâ€™analyse de corrÃ©lation et importance des features numÃ©riques.
